# Project Details

# Title: 
Weakly Supervised Learning for Industrial Optical Inspection. <br />This is work done for one of class projects for graduate level course - CS 591 Algorithms for Data Guided Business Intelligence.

In this class project, worked on developing a model to detect defects by employing Industrial Optical Inspection data on Textured Surfaces. Approached this problem as an Image Segmentation task.

# Approach: 
Deep learning approach followed is based on the paper U-Net: Convolutional Networks for Biomedical Image Segmentation

# Competition
The competition (DAGM 2007 symposium) was inspired by the fact that automated optical inspection allows to reduce the cost of industrial quality control significantly. The competitors had to design a classification algorithm which:

* Detects miscellaneous defects on various statistically textured backgrounds.
* Learns to discern defects automatically from a weakly labelled training data.
* Works on data whose exact characteristics are unknown at development time.
* Adapts all parameters automatically and does not require any human intervention.
* Has a moderate running time (in this competition 24 hours for training and 12 hours for the test phase).
* Takes into account asymmetric costs for false positive and false negative decisions (1:20 was used for the competition).

# Data description:
The data is artificially generated, but similar to real world problems. The first six out of ten datasets, denoted as development datasets, are supposed to be used for algorithm development. The remaining four datasets, which are referred to as competition datasets, can be used to evaluate the performance. Researchers should consider not using or analyzing the competition datasets before the development is completed as a code of honour.

# Some details about the dataset:
* Each development (competition) dataset consists of 1000 (2000) 'non-defective' and of 150 (300) 'defective' images saved in grayscale 8-bit PNG format.
* Each dataset is generated by a different texture model and defect model.
* 'Non-defective' images show the background texture without defects, 'defective' images have exactly one
labelled defect on the background texture.
* All datasets has been randomly split into a training and testing sub-dataset of equal size.
* Weak labels are provided as ellipses roughly indicating the defective area. Technically, defective images are
augmented with a separate grayscale 8-bit image in the PNG format located in a folder 'Label'. The values 0 and 255 denote background and defective area, respectively.

# Resources:
1. Keras
2. Google Colab
3. GPUs on Google Colab
4. Dataset: https://hci.iwr.uni-heidelberg.de/node/3616

# References:
1. Introduction to CNNs â€“ Jianxin Wu
2. Keras tutorial
a. https://keras.io
b. https://keras.io/getting-started/sequential-model-guide/
3. U-Net paper - https://arxiv.org/abs/1505.04597
4. Dice Coefficient - https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient
5. https://hci.iwr.uni-heidelberg.de/node/3616
